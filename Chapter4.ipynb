{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "予測結果: [0 1 1 0]\n正解率: 1.0\n"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# XORの演算結果・学習器に与える入力データ\n",
    "xor_data = [\n",
    "    # P, Q, result\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,0],\n",
    "]\n",
    "\n",
    "# 学習させるためにデータとラベルに分割\n",
    "data = []\n",
    "label = []\n",
    "for row in xor_data:\n",
    "    p = row[0]\n",
    "    q = row[1]\n",
    "    r = row[2]\n",
    "    data.append([p,q])\n",
    "    label.append(r)\n",
    "\n",
    "# データの学習\n",
    "clf = svm.SVC()\n",
    "clf.fit(data, label)\n",
    "\n",
    "# データの予測\n",
    "pre = clf.predict(data)\n",
    "print('予測結果:', pre)\n",
    "\n",
    "# 正解とあっているか確認\n",
    "ok = 0\n",
    "total = 0\n",
    "for idx, answer in enumerate(label):\n",
    "    p = pre[idx]\n",
    "    if p == answer: ok += 1\n",
    "    total += 1\n",
    "\n",
    "print('正解率:', ok/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "正解率： 1.0\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "# XORの演算結果\n",
    "xor_input = [\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,0],\n",
    "]\n",
    "\n",
    "# 入力を学習データとラベルに分ける\n",
    "xor_df = pd.DataFrame(xor_input)\n",
    "xor_data = xor_df.loc[:,[0,1]] # データ2列\n",
    "xor_label = xor_df.loc[:,2] # ラベル 1列(3列目)\n",
    "\n",
    "# print\n",
    "# xor_data\n",
    "# xor_label\n",
    "\n",
    "# データの学習と予測\n",
    "clf = svm.SVC()\n",
    "clf.fit(xor_data, xor_label)\n",
    "pre = clf.predict(xor_data)\n",
    "\n",
    "# 正解率を求める\n",
    "ac_socere = metrics.accuracy_score(xor_label, pre)\n",
    "print('正解率：', ac_socere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "正解率： 1.0\n"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random, re\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# データのシャッフル\n",
    "# random.shuffle(iris.data)\n",
    "\n",
    "# データサイズの確認\n",
    "# print('データサイズ:', iris.data.shape)\n",
    "# print('ラベルサイズ:', iris.target.shape)\n",
    "\n",
    "# Dataframe形式でデータ格納\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# データ分割\n",
    "train, test = train_test_split(df, test_size=0.3, shuffle=True)\n",
    "\n",
    "# データとラベルに分割\n",
    "train_data = train.iloc[:,:-1]\n",
    "train_label = train.iloc[:,-1]\n",
    "test_data = test.iloc[:,:-1]\n",
    "test_label = test.iloc[:,-1]\n",
    "\n",
    "# データの学習と予測\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_data,train_label)\n",
    "pre = clf.predict(test_data)\n",
    "\n",
    "# 正解率算出\n",
    "ac_score = metrics.accuracy_score(test_label, pre)\n",
    "print('正解率：', ac_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n60                 5.0               2.0                3.5               1.0\n116                6.5               3.0                5.5               1.8\n144                6.7               3.3                5.7               2.5\n119                6.0               2.2                5.0               1.5\n108                6.7               2.5                5.8               1.8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.5</td>\n      <td>1.8</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>6.7</td>\n      <td>3.3</td>\n      <td>5.7</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>6.0</td>\n      <td>2.2</td>\n      <td>5.0</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>6.7</td>\n      <td>2.5</td>\n      <td>5.8</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "train.iloc[:,:-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "download: http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\ndownload: http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\ndownload: http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\ndownload: http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\ngzip: train-images-idx3-ubyte.gz\ngzip: train-labels-idx1-ubyte.gz\ngzip: t10k-images-idx3-ubyte.gz\ngzip: t10k-labels-idx1-ubyte.gz\nok\n"
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "import gzip, os, os.path\n",
    "\n",
    "savepath = './data/mnist'\n",
    "baseurl = 'http://yann.lecun.com/exdb/mnist'\n",
    "file = [\n",
    "    'train-images-idx3-ubyte.gz',\n",
    "    'train-labels-idx1-ubyte.gz',\n",
    "    't10k-images-idx3-ubyte.gz',\n",
    "    't10k-labels-idx1-ubyte.gz'\n",
    "]\n",
    "\n",
    "# ダウンロード\n",
    "if not os.path.exists(savepath): # パスが存在しない場合作成\n",
    "    os.makedirs(savepath)\n",
    "for f in file:\n",
    "    url = baseurl + '/' + f\n",
    "    loc = savepath + '/' + f\n",
    "    print('download:', url)\n",
    "    if not os.path.exists(loc):\n",
    "        req.urlretrieve(url, loc)\n",
    "\n",
    "# Gzip解凍\n",
    "for f in file:\n",
    "    gz_file = savepath + '/' + f\n",
    "    raw_file = savepath + '/' + f.replace('.gz', '')\n",
    "    print('gzip:', f)\n",
    "    with gzip.open(gz_file, 'rb') as fp: # gzファイル読み込み\n",
    "        body = fp.read()\n",
    "        with open(raw_file, 'wb') as w: # gzファイルを読み込んだあとのバイナリーファイルを書き込み\n",
    "            w.write(body)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータについて\n",
    "- 独自のデータベース形式でデータが格納されている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータをCSV変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toCSV\n",
    "import struct\n",
    "\n",
    "def to_csv(name, maxdata):\n",
    "    # ラベルファイルとイメージファイルを開く\n",
    "    lbl_f = open('./data/mnist/'+ name + '-labels-idx1-ubyte','rb')\n",
    "    img_f = open('./data/mnist/' + name + '-images-idx3-ubyte', 'rb')\n",
    "    csv_f = open('./data/mnist/' + name + '.csv', 'w', encoding='utf-8')\n",
    "    # ヘッダーを読み込む\n",
    "    mag, lbl_count = struct.unpack('>II', lbl_f.read(8))\n",
    "    mag, img_count = struct.unpack('>II', img_f.read(8))\n",
    "    rows, cols = struct.unpack('>II', img_f.read(8))\n",
    "    pixcels = rows*cols\n",
    "    #画像データを読み込んでCSVで保存\n",
    "    res = []\n",
    "    for idx in range(lbl_count):\n",
    "        if idx > maxdata: break\n",
    "        label = struct.unpack('B', lbl_f.read(1))[0]\n",
    "        bdata = img_f.read(pixcels)\n",
    "        sdata = list(map(lambda n: str(n), bdata))\n",
    "        csv_f.write(str(label)+\",\")\n",
    "        csv_f.write(','.join(sdata)+'\\r\\n')\n",
    "        # うまく取り出せたかPGMで保存してテスト\n",
    "        if idx < 10:\n",
    "            s = 'P2 28 28 255\\n'\n",
    "            s += ' '.join(sdata)\n",
    "            iname = './data/mnist/{0}-{1}-{2}.pgm'.format(name,idx,label)\n",
    "            with open(iname, 'w', encoding='utf-8') as f:\n",
    "                f.write(s)\n",
    "    csv_f.close()\n",
    "    lbl_f.close()\n",
    "    img_f.close()\n",
    "\n",
    "#  出力件数を指定\n",
    "to_csv('train',1000)\n",
    "to_csv('t10k', 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "正解率： 0.8842315369261478\nレポート=\n              precision    recall  f1-score   support\n\n           0       0.87      0.98      0.92        42\n           1       0.99      1.00      0.99        67\n           2       0.91      0.89      0.90        55\n           3       0.94      0.72      0.81        46\n           4       0.86      0.93      0.89        55\n           5       0.75      0.82      0.78        50\n           6       0.95      0.81      0.88        43\n           7       0.79      0.94      0.86        49\n           8       0.94      0.82      0.88        40\n           9       0.89      0.87      0.88        54\n\n    accuracy                           0.88       501\n   macro avg       0.89      0.88      0.88       501\nweighted avg       0.89      0.88      0.88       501\n\n"
    }
   ],
   "source": [
    "# MNISTの学習\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "# CSVファイルを読み込んで学習データに成形\n",
    "def load_csv(fname):\n",
    "    labels = []\n",
    "    images = []\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f:\n",
    "            cols = line.split(',')\n",
    "            if len(cols) < 2: continue\n",
    "            labels.append(int(cols.pop(0)))\n",
    "            vals = list(map(lambda n: int(n) / 256, cols))\n",
    "            images.append(vals)\n",
    "    return {'labels':labels, 'images':images}\n",
    "\n",
    "data = load_csv('./data/mnist/train.csv')\n",
    "test = load_csv('./data/mnist/t10k.csv')\n",
    "\n",
    "# 学習\n",
    "clf = svm.SVC()\n",
    "clf.fit(data['images'], data['labels'])\n",
    "\n",
    "# 予測\n",
    "predict = clf.predict(test['images'])\n",
    "\n",
    "# 結果がどの程度合っていたか確認\n",
    "ac_score = metrics.accuracy_score(test['labels'], predict)\n",
    "cl_report = metrics.classification_report(test['labels'], predict)\n",
    "print('正解率：', ac_score)\n",
    "print('レポート=')\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "正解率= 1.0\n"
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# テキストを読んで出現頻度を調べる\n",
    "def check_freq(fname):\n",
    "    name = os.path.basename(fname)\n",
    "    lang = re.match(r'^[a-z]{2,}', name).group()\n",
    "    with open(fname, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = text.lower() # 小文字に変換\n",
    "    # カウンタを初期化\n",
    "    cnt = [0 for n in range(0,26)] #アルファベット分のリスト作成\n",
    "    code_a = ord('a') # unicode point取得\n",
    "    code_z = ord('z')\n",
    "    # アルファベットの出現回数を調べる\n",
    "    for ch in text:\n",
    "        n = ord(ch)\n",
    "        if code_a <= n <= code_z:   # a-zの間かどうか\n",
    "            cnt[n-code_a] += 1\n",
    "    # 正規化する\n",
    "    total = sum(cnt)\n",
    "    freq = list(map(lambda n: n/total, cnt)) # cntの要素ごとに頻度を算出 map(func, *iterative)\n",
    "    return (freq, lang)\n",
    "\n",
    "# 各ファイルを処理する\n",
    "def load_files(path):\n",
    "    freqs = []\n",
    "    labels = []\n",
    "    file_list = glob.glob(path)\n",
    "    for fname in file_list:\n",
    "        r = check_freq(fname)\n",
    "        freqs.append(r[0])\n",
    "        labels.append(r[1])\n",
    "    return {'freqs':freqs, 'labels':labels}\n",
    "\n",
    "data = load_files('./data/lang/train/*.txt')\n",
    "test = load_files('./data/lang/test/*.txt')\n",
    "\n",
    "# 今後のためにJSONで結果を保存\n",
    "with open('./data/lang/freq.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump([data, test], fp)\n",
    "\n",
    "# 学習\n",
    "clf = svm.SVC()\n",
    "clf.fit(data['freqs'],data['labels'])\n",
    "\n",
    "# 予測\n",
    "predict = clf.predict(test['freqs'])\n",
    "\n",
    "# 結果がどの程度あっていたか\n",
    "as_score = metrics.accuracy_score(test['labels'], predict)\n",
    "cl_report = metrics.classification_report(test['labels'],predict)\n",
    "print('正解率=', as_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594597574228",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "finished download\n"
    }
   ],
   "source": [
    "# 1-1 データのダウンロード\n",
    "# urlli\n",
    "\n",
    "# ライブラリの取り込み\n",
    "import urllib.request\n",
    "\n",
    "# URLと保存パスを指定\n",
    "url = 'https://uta.pw/shodou/img/28/214.png'\n",
    "savename = '../data/test.png'\n",
    "\n",
    "# Download\n",
    "urllib.request.urlretrieve(url, savename)\n",
    "print('finished download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "finished download\n"
    }
   ],
   "source": [
    "# urlopen()を使用する方法\n",
    "# Import library\n",
    "import urllib.request\n",
    "\n",
    "# setting\n",
    "url = 'https://uta.pw/shodou/img/28/214.png'\n",
    "savename = '../data/test2_urlopen.png'\n",
    "\n",
    "# download\n",
    "mem = urllib.request.urlopen(url).read() # メモリー上にデータが展開(binary)\n",
    "\n",
    "# save a file\n",
    "with open(savename, mode='wb') as f: # binaryのためb\n",
    "    f.write(mem)\n",
    "    print('finished download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ip]\nAPI_URI=http://api.aoikujira.com/ip/get.php\nREMOTE_ADDR=126.243.78.33\nREMOTE_HOST=softbank126243078033.bbtec.net\nREMOTE_PORT=48690\nHTTP_HOST=api.aoikujira.com\nHTTP_USER_AGENT=Python-urllib/3.7\nHTTP_ACCEPT_LANGUAGE=\nHTTP_ACCEPT_CHARSET=\nSERVER_PORT=443\nFORMAT=ini\n\n\n"
    }
   ],
   "source": [
    "# Webからデータを取得\n",
    "# クジラWeb API : https://api.aoikujira.com/\n",
    "# クライアントの接続情報を表示\n",
    "# IP確認ＡＰＩへアクセスして結果を表示\n",
    "# Import module\n",
    "import urllib.request\n",
    "\n",
    "# setting\n",
    "url = 'https://api.aoikujira.com/ip/ini'\n",
    "\n",
    "# Get data\n",
    "res = urllib.request.urlopen(url)\n",
    "data = res.read()\n",
    "\n",
    "# translate binary data\n",
    "text = data.decode('utf-8')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "url = https://api.aoikujira.com/zip/xml/get.php?fmt=xml&zn=1500042\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<address result=\"1\">\n<header>\n  <result>1</result>\n  <api>api.aoikujira.com/zip</api>\n  <version>1.1</version>\n</header>\n<value>\n  <zip>1500042</zip>\n  <ken>東京都</ken>\n  <shi>渋谷区</shi>\n  <cho>宇田川町</cho>\n  <disp>東京都渋谷区宇田川町</disp>\n  <kenkana>トウキョウト</kenkana>\n  <shikana>シブヤク</shikana>\n  <chokana>ウダガワチョウ</chokana>\n</value>\n</address>\n"
    }
   ],
   "source": [
    "# 任意のパラメータを付けてリクエストを送信する方法\n",
    "# 住所検索APIのエントリーポイント\n",
    "# パラメータ: fmt - formatの指定(json, xml), zn - 郵便番号を指定\n",
    "# Import module\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "API ='https://api.aoikujira.com/zip/xml/get.php'\n",
    "\n",
    "# パラメータをURLエンコードする\n",
    "values = {\n",
    "    'fmt': 'xml',\n",
    "    'zn': '1500042'\n",
    "}\n",
    "params = urllib.parse.urlencode(values)\n",
    "\n",
    "# リクエスト用のURL生成\n",
    "url = API + \"?\" + params\n",
    "print('url =', url)\n",
    "\n",
    "# download\n",
    "data = urllib.request.urlopen(url).read()\n",
    "text = data.decode('utf-8')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memo\n",
    "- URLパラメータの与え方：末尾に'?'を書いて、key=valueの形式で記述。複数与える場合は'&'で繋げる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "url = https://api.aoikujira.com/hyakunin/get.php?fmt=ini&key=%E3%81%A1%E3%81%8E%E3%82%8A%E3%81%8D%E3%81%AA\n[item42]\nkami=ちぎりきな かたみに袖を しぼりつつ\nsimo=末の松山 波こさじとは\nkami_kana=ちきりきなかたみにそてをしほりつつ\nsimo_kana=すゑのまつやまなみこさしとは\nsakusya=清原元輔\n\n\n"
    }
   ],
   "source": [
    "# 百人一首を検索するコマンドを自作してみる\n",
    "# エントリポイント: https://api.aoikujira.com/hyakunin/get.php\n",
    "# parameters\n",
    "# fmt : ini | xml | json\n",
    "# key : search keywords\n",
    "\n",
    "# Import module\n",
    "import sys\n",
    "import urllib.request as req\n",
    "import urllib.parse as parse\n",
    "\n",
    "# # コマンドライン引数を得る -- カット\n",
    "# if len(sys.argv) <= 1:\n",
    "#     print('USAGE: hyakunin.py (keyword)')\n",
    "#     sys.exit()\n",
    "# keyword = sys.argv[1]\n",
    "# keyword = '秋の田'\n",
    "keyword = 'ちぎりきな'\n",
    "\n",
    "# パラメータをエンコード\n",
    "API = 'https://api.aoikujira.com/hyakunin/get.php'\n",
    "query = {\n",
    "    'fmt':'ini',\n",
    "    'key':keyword\n",
    "}\n",
    "params = parse.urlencode(query)\n",
    "url = API + '?' + params\n",
    "print('url =', url)\n",
    "\n",
    "# download\n",
    "with req.urlopen(url) as r:\n",
    "    binarydata = r.read()\n",
    "    text = binarydata.decode('utf-8')\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "スクレイピングとは?\nWebページを解析すること\n任意の箇所を抽出すること\n"
    }
   ],
   "source": [
    "# 1-2 BeautifulSoup\n",
    "# 基本的な使い方\n",
    "# Import module\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 解析したXML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1>スクレイピングとは?</h1>\n",
    "    <p>Webページを解析すること</p>\n",
    "    <p>任意の箇所を抽出すること</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 任意の部分を抽出する\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "# 要素をテキスト表示\n",
    "print(h1.string)\n",
    "print(p1.string)\n",
    "print(p2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "title =スクレイピングとは\nbody =Webページから任意のデータを抽出すること\n"
    }
   ],
   "source": [
    "# 任意のidで要素を探す方法\n",
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1 id=\"title\">スクレイピングとは</h1>\n",
    "    <p id=\"body\">Webページから任意のデータを抽出すること</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find()メソッドで取り出す\n",
    "title = soup.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "\n",
    "# テキスト部分表示\n",
    "print('title =' + title.string)\n",
    "print('body =' + body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "uta > https://uta.pw\noto > https://oto.chu.jp\n"
    }
   ],
   "source": [
    "# 複数の要素を取得する-find_all()\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html =\"\"\"\n",
    "<html><body>\n",
    "    <ul>\n",
    "        <li><a href=\"https://uta.pw\">uta</a></li>\n",
    "        <li><a href=\"https://oto.chu.jp\">oto</a></li>\n",
    "    </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find_all()\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# リンク一覧を表示\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, '>', href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "東京都 渋谷区 宇田川町\n"
    }
   ],
   "source": [
    "# urlopen()とBeautifulSoupの組み合わせ\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = 'https://api.aoikujira.com/zip/xml/1500042'\n",
    "\n",
    "# urlopen()でデータ取得\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# Beautifulsoupで解析\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "\n",
    "# 任意のデータ抽出\n",
    "ken = soup.find(\"ken\").string\n",
    "shi = soup.find(\"shi\").string\n",
    "cho = soup.find(\"cho\").string\n",
    "print(ken, shi, cho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "h1 = トルストイの名言\nli = 汝の心に教えよ、心に学ぶな。\nli = 謙虚な人は誰からも好かれる。\nli = 強い人々は、いつも気取らない。\n"
    }
   ],
   "source": [
    "# CSSセレクターを使う\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# html\n",
    "html =\"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "    <h1>トルストイの名言</h1>\n",
    "    <ul class=\"items\">\n",
    "        <li>汝の心に教えよ、心に学ぶな。</li>\n",
    "        <li>謙虚な人は誰からも好かれる。</li>\n",
    "        <li>強い人々は、いつも気取らない。</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# html解析\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 必要な部分をCSSクエリで取り出す\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print('h1 =',h1)\n",
    "\n",
    "# リスト部分を取得\n",
    "li_list = soup.select('div#meigen > ul.items > li')\n",
    "for li in li_list:\n",
    "    print('li =', li.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usdjpy = 107.240000\n"
    }
   ],
   "source": [
    "# Yahooファイナンス\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import urllib.request as req\n",
    "\n",
    "# html取得\n",
    "url = \"https://stocks.finance.yahoo.co.jp/stocks/detail/?code=usdjpy\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML解析\n",
    "s = soup(res, 'html.parser')\n",
    "\n",
    "# 任意のデータ抽出\n",
    "price = s.select_one(\".stoksPrice\").string\n",
    "print('usdjpy =', price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-64618af17684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 為替レートxml取得 kujira\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'https://api.aoikujira.com/kawase/xml/usd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# html解析\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# 為替レートxml取得 kujira\n",
    "url ='https://api.aoikujira.com/kawase/xml/usd' # serverが停止\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# html解析\n",
    "sp = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "jpy = sp.select_one('jpy').string\n",
    "print('jpy =',jpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<http.client.HTTPResponse at 0x25fa57aedc8>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# 1-3 CSSセレクターについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbasecondaa456a6740d7e490db9ca4374186e9e5a",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}